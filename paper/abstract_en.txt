This paper introduces "ALL2Vec", a conceptual framework proposing that all modalities processed by intelligent systems—language, vision, sound, and other sensory or symbolic data—are fundamentally representable within a single unified vector space. The hypothesis arises from the observation that systems based on perceptron-like architectures inevitably interpret input as vectors, implying that any form of cognition, including that of the human brain, operates within a shared vectorized meaning space.

From this perspective, the paper argues that Artificial General Intelligence (AGI) should not treat multimodal processing as the integration of heterogeneous representations, but rather as different projections within one continuous semantic manifold. The "ALL2Vec" philosophy therefore suggests that the essential step toward AGI is not merely scaling models, but achieving structural unification of meaning through a universal vector space. This framework positions the unified vector space as a fundamental architectural component for future AGI development, aligning with the hypothesis that human consciousness itself arises from such representational coherence.
